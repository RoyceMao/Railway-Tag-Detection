{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== 读取图片信息 ========\n",
      "class_count:\n",
      "{'0': 24,\n",
      " '1': 10,\n",
      " '2': 21,\n",
      " '3': 102,\n",
      " '4': 20,\n",
      " '5': 20,\n",
      " '6': 30,\n",
      " '7': 35,\n",
      " '8': 76,\n",
      " '9': 36,\n",
      " 'bg': 0}\n",
      "类别数量：11\n",
      "训练集数量：120\n",
      "测试集数量：0\n",
      "\n",
      "======== 保存配置 ========\n",
      "配置参数已写入：config.pickle,\n",
      "\n",
      "======== 加载预训练模型参数 ========\n",
      "loading weights from ./model/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "\n",
      "======== 开始训练 ========\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 149s 1s/step - rpn_cls: 0.1058 - rpn_regr: 0.0338 - detector_cls: 0.7696 - detector_regr: 0.1717\n",
      "Loss RPN classifier: 0.07375852511487821\n",
      "Loss RPN regression: 0.03092568395562315\n",
      "Loss Detector classifier: 0.5778397411108017\n",
      "Loss Detector regression: 0.07608750903358062\n",
      "Elapsed time: 148.6282205581665\n",
      "Total loss decreased from inf to 0.7586114592148837, saving weights\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 138s 1s/step - rpn_cls: 0.0456 - rpn_regr: 0.0279 - detector_cls: 0.3893 - detector_regr: 0.0814\n",
      "Loss RPN classifier: 0.03794629643358928\n",
      "Loss RPN regression: 0.02462094008794035\n",
      "Loss Detector classifier: 0.5122654919823011\n",
      "Loss Detector regression: 0.10171730006113648\n",
      "Elapsed time: 141.74072194099426\n",
      "Total loss decreased from 0.7586114592148837 to 0.6765500285649672, saving weights\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 139s 1s/step - rpn_cls: 0.0453 - rpn_regr: 0.0214 - detector_cls: 0.5534 - detector_regr: 0.0310\n",
      "Loss RPN classifier: 0.03764123749128161\n",
      "Loss RPN regression: 0.02011318124399016\n",
      "Loss Detector classifier: 0.49059534122546516\n",
      "Loss Detector regression: 0.023462171953481933\n",
      "Elapsed time: 138.60745191574097\n",
      "Total loss decreased from 0.6765500285649672 to 0.5718119319142189, saving weights\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 138s 1s/step - rpn_cls: 0.0453 - rpn_regr: 0.0187 - detector_cls: 0.4668 - detector_regr: 0.0213\n",
      "Loss RPN classifier: 0.03764123900987785\n",
      "Loss RPN regression: 0.01707121575045676\n",
      "Loss Detector classifier: 0.4302374357978503\n",
      "Loss Detector regression: 0.01801823714825635\n",
      "Elapsed time: 138.4673855304718\n",
      "Total loss decreased from 0.5718119319142189 to 0.5029681277064413, saving weights\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 138s 1s/step - rpn_cls: 0.0453 - rpn_regr: 0.0148 - detector_cls: 0.4683 - detector_regr: 0.0131\n",
      "Loss RPN classifier: 0.037643408903135146\n",
      "Loss RPN regression: 0.013465555066189457\n",
      "Loss Detector classifier: 0.45524999300638835\n",
      "Loss Detector regression: 0.01348055384393471\n",
      "Elapsed time: 138.5772774219513\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 138s 1s/step - rpn_cls: 0.0453 - rpn_regr: 0.0068 - detector_cls: 0.5000 - detector_regr: 0.0159\n",
      "Loss RPN classifier: 0.03764388153159537\n",
      "Loss RPN regression: 0.007122219207485614\n",
      "Loss Detector classifier: 0.4827774927020073\n",
      "Loss Detector regression: 0.014163932687370106\n",
      "Elapsed time: 138.40164399147034\n",
      "Epoch 7/10\n",
      " 53/120 [============>.................] - ETA: 1:17 - rpn_cls: 0.0379 - rpn_regr: 0.0066 - detector_cls: 0.5744 - detector_regr: 0.0067post_num:0,bg_num:0,ignore_num:18000\n",
      "120/120 [==============================] - 138s 1s/step - rpn_cls: 0.0453 - rpn_regr: 0.0088 - detector_cls: 0.5012 - detector_regr: 0.0065\n",
      "Loss RPN classifier: 0.037642420693561024\n",
      "Loss RPN regression: 0.00871170282989624\n",
      "Loss Detector classifier: 0.4394016017516454\n",
      "Loss Detector regression: 0.005617996499252816\n",
      "Elapsed time: 138.36474657058716\n",
      "Total loss decreased from 0.5029681277064413 to 0.49137372177435545, saving weights\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 138s 1s/step - rpn_cls: 0.0453 - rpn_regr: 0.0043 - detector_cls: 0.5204 - detector_regr: 0.0113\n",
      "Loss RPN classifier: 0.0376493870844614\n",
      "Loss RPN regression: 0.004990649012931196\n",
      "Loss Detector classifier: 0.49418069794774055\n",
      "Loss Detector regression: 0.010456428034619119\n",
      "Elapsed time: 138.5027265548706\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 138s 1s/step - rpn_cls: 0.0453 - rpn_regr: 0.0058 - detector_cls: 0.5102 - detector_regr: 0.0120\n",
      "Loss RPN classifier: 0.03764164786459469\n",
      "Loss RPN regression: 0.006566465655729796\n",
      "Loss Detector classifier: 0.4744916061560313\n",
      "Loss Detector regression: 0.011028675575895855\n",
      "Elapsed time: 138.42708826065063\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 138s 1s/step - rpn_cls: 0.0453 - rpn_regr: 0.0052 - detector_cls: 0.4381 - detector_regr: 0.0083\n",
      "Loss RPN classifier: 0.03764969013049243\n",
      "Loss RPN regression: 0.006611183385878879\n",
      "Loss Detector classifier: 0.49225524912277857\n",
      "Loss Detector regression: 0.008511666156118735\n",
      "Elapsed time: 138.44020462036133\n",
      "[146, 99, 111, 605, 139, 181, 256, 235, 419, 186]\n",
      "Training complete, exiting.\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "import random\n",
    "import pprint\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "import config\n",
    "import data_generators\n",
    "import losses as losses_fn\n",
    "import roi_helpers as roi_helpers\n",
    "from keras.utils import generic_utils\n",
    "import resnet as nn\n",
    "from simple_parser import get_data\n",
    "from props_pic_2nd import props_pic\n",
    "from Visual import _create_unique_color_float, _create_unique_color_uchar, draw_boxes_and_label_on_image\n",
    "from anchor_2nd import anchors_generation, sliding_anchors_all, pos_neg_iou, anchor_targets_bbox\n",
    "from net_design_2nd import stage_2_net_res\n",
    "import matplotlib as mpl\n",
    "mpl.use('agg')\n",
    "np.set_printoptions(threshold=np.inf) # 允许numpy数组的完全打印\n",
    "np.seterr(divide='ignore', invalid='ignore') # 不允许“divide”Warning相关信息的打印\n",
    "\n",
    "def data_gen_stage_2(result, img_data, sess, X, class_mapping, classes_count, iter_num, num_logistic):\n",
    "    \"\"\"\n",
    "    根据1阶段的一个batch（1张）图片处理结果，生成第2阶段的训练数据\n",
    "    :param result: \n",
    "    :param img_data: \n",
    "    :param sess: \n",
    "    :param X: \n",
    "    :param class_mapping: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    # feature map上的proposals坐标映射回resize原图(16倍下采样)\n",
    "    result[:, :] = 16 * result[:, :]\n",
    "    # 提取第1阶段每个batch图片对应的Tag标签标注\n",
    "    x1_tag = img_data['outer_boxes'][0]['x1']\n",
    "    y1_tag = img_data['outer_boxes'][0]['y1']\n",
    "    x2_tag = img_data['outer_boxes'][0]['x2']\n",
    "    y2_tag = img_data['outer_boxes'][0]['y2']\n",
    "    cls_tag = img_data['outer_boxes'][0]['class']\n",
    "    # 提取第1阶段每个batch图片对应的数字标签标注\n",
    "    annos_list = [[], [], [], [], []]\n",
    "    for i in range(len(img_data['bboxes'])):\n",
    "        # 对无法辨别的小数字标注（高、宽均低于原图的10个像素点）做剔除，防止影响最终检测效果\n",
    "        if img_data['bboxes'][i]['x2'] - img_data['bboxes'][i]['x1'] >= 10 and img_data['bboxes'][i]['y2'] - \\\n",
    "                img_data['bboxes'][i]['y1'] >= 10:\n",
    "            annos_list[0].append(img_data['bboxes'][i]['x1'])\n",
    "            annos_list[1].append(img_data['bboxes'][i]['y1'])\n",
    "            annos_list[2].append(img_data['bboxes'][i]['x2'])\n",
    "            annos_list[3].append(img_data['bboxes'][i]['y2'])\n",
    "            annos_list[4].append(img_data['bboxes'][i]['class'])\n",
    "    annos_np = np.concatenate((np.array(annos_list[0])[np.newaxis, :], np.array(annos_list[1])[np.newaxis, :],\n",
    "                               np.array(annos_list[2])[np.newaxis, :], np.array(annos_list[3])[np.newaxis, :],\n",
    "                               np.array(annos_list[4])[np.newaxis, :]), axis=0).T\n",
    "    # 进行第2阶段所需参数的计算提取过程\n",
    "    rs_pic, rs_boxes, rs_num_gt_pic, rs_wh, gt_index = props_pic(sess, result[np.newaxis, :, :],\n",
    "                                                                 [[x1_tag, y1_tag, x2_tag, y2_tag, cls_tag]],\n",
    "                                                                 annos_np[np.newaxis, :, :], X[np.newaxis, :, :, :])\n",
    "    # ==============================================================================\n",
    "    # 生成第二阶段的训练数据\n",
    "    # ==============================================================================\n",
    "    batch_size = len(rs_pic[0])  # 一次5张crops图\n",
    "    base_anchors = anchors_generation(16, [0.5 ** (1.0 / 3.0), 1, 2 ** (1.0 / 3.0)],\n",
    "                                      [0.5, 0.5 ** (1.0 / 2.0), 1, 2 ** (1.0 / 3.0), 2 ** (1.0 / 2.0), 2])\n",
    "    all_anchors = sliding_anchors_all((10, 20), (8, 8), base_anchors)\n",
    "    #================================================================\n",
    "    '''\n",
    "    # 测试部分：计算当前anchor与当前gt-box的iou，以及框住gt的proposals生成的anchors是否覆盖了所有的小gt\n",
    "    from overlap_2nd import overlap\n",
    "    if gt_index != [[]]:\n",
    "        for gt in rs_num_gt_pic[0][gt_index[0][0]]:\n",
    "            num_width.append(gt[2]-gt[0])\n",
    "            num_height.append(gt[3]-gt[1])\n",
    "    \n",
    "        # 打印Top-5的最高IOU值\n",
    "        for anchor in all_anchors:\n",
    "            for gt in  rs_num_gt_pic[0][gt_index[0][0]]:\n",
    "                if overlap(anchor[np.newaxis, :], gt[np.newaxis, :])[0][0] > max:\n",
    "                    max = overlap(anchor[np.newaxis, :], gt[np.newaxis, :])[0][0]\n",
    "        print(\"\\nTop-{}最高IOU值：{}\\n\".format(gt_index[0][0]+1,max))\n",
    "    '''\n",
    "\n",
    "    # print(\"\\n宽均值：{}、高均值：{}、宽_max：{}、高_max：{}、宽_min：{}、高_min：{}、高宽比_max：{}、高宽比_min：{}\".format(mean_width,mean_height,max_width,max_height,min_width,min_height,max_ratio,min_ratio))\n",
    "    # print(np.array(rs_num_gt_pic[0]))\n",
    "    # ================================================================\n",
    "    labels_batch, regression_batch, boxes_batch, inds, pos_inds = anchor_targets_bbox(all_anchors, rs_pic[0],\n",
    "                                                                                      rs_num_gt_pic[0],\n",
    "                                                                                      len(class_mapping) - 1)\n",
    "\n",
    "    # 测试部分：输出第2阶段小图片的正样本anchors情况\n",
    "    for i, num_gt in enumerate(rs_num_gt_pic[0]):\n",
    "        if i in gt_index[0]:\n",
    "            for num in rs_num_gt_pic[0][i][:,4]:\n",
    "                num_logistic[int(num)] += 1\n",
    "            draw_imgs = draw_boxes_and_label_on_image(rs_pic[0][i],\n",
    "                                                      {1: all_anchors[pos_inds[i]]}) # , {1: num_gt}\n",
    "            cv2.imwrite('./anchors_test/Pic{}_Prop{}.png'.format(iter_num, i),\n",
    "                        draw_imgs)\n",
    "\n",
    "    #============================================================\n",
    "    #============================================================\n",
    "    x1 = rs_pic[0]  # tf.tensor转换为numpy\n",
    "    # Y1 = [labels_batch, regression_batch]\n",
    "\n",
    "    # 区分训练过程中计算loss的anchors样本，并提取非背景类的anchors索引\n",
    "    # ===========rpn_accuracy_rpn_monitor.append(len(inds[0]))\n",
    "    # ===========rpn_accuracy_for_epoch.append(len(inds[0]))\n",
    "\n",
    "    # 训练分类网络\n",
    "    # y1目标数据\n",
    "    labels_batch[inds, -1] = np.abs(labels_batch[inds, -1] - 1)  # 0、1标注减1再取绝对值，相当于把labels_batch第3维最后1列由前景背景类替换为bg类\n",
    "    # labels_batch[:, :, -1] = np.abs(labels_batch[:, :, -1]) # 然后所有最后1列取绝对值把中性样本也替换为bg类\n",
    "    # 正、负样本与中性样本的区分numpy\n",
    "    tmp = np.zeros((batch_size, len(inds[0]), 1))\n",
    "    for batch in range(len(inds)):\n",
    "        for i in range(len(inds[0])):\n",
    "            a = np.zeros(1)\n",
    "            # print(labels_batch[:, inds[0], -1])\n",
    "            if labels_batch[:, :, -1][batch][i] != -1:  # 说明是非忽略样本\n",
    "                a = 1\n",
    "            tmp[batch][i] = a\n",
    "    y1 = np.concatenate([tmp, labels_batch], axis=2)\n",
    "    # y2目标数据\n",
    "    tmp = np.zeros((batch_size, len(inds[0]), 4 * (len(classes_count) - 1)))\n",
    "    for batch in range(len(inds)):\n",
    "        for i in range(len(inds[0])):\n",
    "            a = np.zeros(4 * (len(classes_count) - 1))\n",
    "            # print(labels_batch[:, inds[0], -1])\n",
    "            if labels_batch[:, :, -1][batch][i] == 0:  # 说明是正样本\n",
    "                # 取出正样本赋值标签为1的类别索引\n",
    "                label_index = list(labels_batch[:, :, :(len(classes_count) - 1)][batch][i]).index(1)\n",
    "                # 然后把对应的正样本回归目标进行对应类别下的赋值\n",
    "                a[4 * label_index: 4 * label_index + 4] = regression_batch[:, :, :4][batch][i]\n",
    "            tmp[batch][i] = a\n",
    "\n",
    "    # 合并为list\n",
    "    y2 = np.concatenate([np.repeat(labels_batch[:, :, :(len(classes_count) - 1)], 4, axis=2), tmp], axis=2)\n",
    "    del x1_tag,y1_tag,x2_tag,y2_tag,cls_tag,annos_list,annos_np,rs_pic,rs_boxes,rs_num_gt_pic,rs_wh,gt_index,labels_batch,regression_batch,boxes_batch,inds,pos_inds,tmp\n",
    "    gc.collect()\n",
    "    return np.array(x1), [y1,y2], num_logistic\n",
    "\n",
    "\n",
    "def train():\n",
    "    cfg = config.Config()\n",
    "\n",
    "    # 下面3行设置了数据增强时所需相关参数\n",
    "    cfg.use_horizontal_flips = True\n",
    "    cfg.use_vertical_flips = True\n",
    "    cfg.rot_90 = True\n",
    "\n",
    "    cfg.base_net_weights = os.path.join('./model/', nn.get_weight_path())\n",
    "    # cfg.model_path = './model/kitti_frcnn_last.hdf5'\n",
    "    cfg.simple_label_file = 'img_infos.txt'\n",
    "\n",
    "    # 读取VOC图片数据\n",
    "    print('======== 读取图片信息 ========')\n",
    "    all_images, classes_count, class_mapping = get_data(cfg.simple_label_file)\n",
    "    # 增加背景类（若没有）\n",
    "    if 'bg' not in classes_count:\n",
    "        classes_count['bg'] = 0\n",
    "        class_mapping['bg'] = len(class_mapping)\n",
    "\n",
    "    cfg.class_mapping = class_mapping\n",
    "\n",
    "    print('class_count:')\n",
    "    pprint.pprint(classes_count)\n",
    "    print('类别数量：{}'.format(len(classes_count)))\n",
    "\n",
    "    # # 打乱图片顺序\n",
    "    # random.shuffle(all_images)\n",
    "\n",
    "    # 分配训练集和测试\n",
    "    train_imgs = [s for s in all_images if s['imageset'] == 'trainval']\n",
    "    val_imgs = [s for s in all_images if s['imageset'] == 'test']\n",
    "\n",
    "    print('训练集数量：{}'.format(len(train_imgs)))\n",
    "    print('测试集数量：{}'.format(len(val_imgs)))\n",
    "\n",
    "    # 保存配置文件\n",
    "    print('\\n======== 保存配置 ========')\n",
    "    with open(cfg.config_save_file, 'wb') as config_f:\n",
    "        pickle.dump(cfg, config_f)\n",
    "        print('配置参数已写入：{},'.format(cfg.config_save_file))\n",
    "\n",
    "    # 返回数据生成器\n",
    "    data_gen_train = data_generators.get_anchor_gt(train_imgs, cfg, nn.get_img_output_length,\n",
    "                                                   K.image_dim_ordering(), mode='train')\n",
    "    # data_gen_val = data_generators.get_anchor_gt(val_imgs, cfg, nn.get_img_output_length,\n",
    "    #                                              K.image_dim_ordering(), mode='val')\n",
    "\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        input_shape_img = (3, None, None)\n",
    "    else:\n",
    "        input_shape_img = (None, None, 3)\n",
    "\n",
    "    img_input = Input(shape=input_shape_img)\n",
    "    small_img_input = Input(shape=(160, 80, 3)) # 高为80，宽为40\n",
    "\n",
    "    # 定义基础网络\n",
    "    shared_layers = nn.nn_base(img_input, trainable=True)\n",
    "\n",
    "    # 定义rpn网络\n",
    "    num_anchors = len(cfg.anchor_box_scales) * len(cfg.anchor_box_ratios)  # 9\n",
    "    rpn = nn.rpn(shared_layers, num_anchors)\n",
    "\n",
    "    # 定义后续分类网络的输出\n",
    "    classifier = stage_2_net_res(len(classes_count), small_img_input, height=160, width=80)\n",
    "\n",
    "    model_rpn = Model(img_input, rpn[:2])\n",
    "    model_classifier = Model(small_img_input, classifier)\n",
    "\n",
    "    # model_all = Model([img_input, small_img_input], rpn[:2] + classifier)\n",
    "\n",
    "    # 加载预训练模型参数\n",
    "    print('\\n======== 加载预训练模型参数 ========')\n",
    "    try:\n",
    "        print('loading weights from {}'.format(cfg.base_net_weights))\n",
    "        model_rpn.load_weights(cfg.base_rpn_model_path, by_name=True)\n",
    "        model_classifier.load_weights(cfg.base_tf_model_path, by_name=True)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('Could not load pretrained model weights. Weights can be found in the keras application folder '\n",
    "              'https://github.com/fchollet/keras/tree/master/keras/applications')\n",
    "\n",
    "    # 编译模型\n",
    "    optimizer = Adam(lr=1e-5)\n",
    "    optimizer_classifier = Adam(lr=1e-3)\n",
    "    model_rpn.compile(optimizer=optimizer,\n",
    "                      loss=[losses_fn.rpn_loss_cls(num_anchors), losses_fn.rpn_loss_regr(num_anchors)],\n",
    "                      metrics=['accuracy'])\n",
    "    model_classifier.compile(optimizer=optimizer_classifier,\n",
    "                             loss=[losses_fn.class_loss_cls, losses_fn.class_loss_regr(len(classes_count) - 1)],\n",
    "                             metrics=['accuracy'])\n",
    "    # model_all.compile(optimizer='sgd', loss='mae')\n",
    "\n",
    "    # 设置一些训练参数\n",
    "    epoch_length = 910\n",
    "    num_epochs = 200\n",
    "    losses = np.zeros((epoch_length, 5))\n",
    "    rpn_accuracy_rpn_monitor = []\n",
    "    rpn_accuracy_for_epoch = []\n",
    "    start_time = time.time()\n",
    "    best_loss = np.Inf\n",
    "    iter_num = 0\n",
    "    # 解决tensorflow初始化参数内存占满的问题\n",
    "    # config_tf = tf.ConfigProto()\n",
    "    # config_tf.gpu_options.allow_growth = True\n",
    "    sess = tf.Session() # config=config_tf\n",
    "    num_logistic = [0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "    print('\\n======== 开始训练 ========')\n",
    "    for epoch_num in range(num_epochs):\n",
    "        progbar = generic_utils.Progbar(epoch_length)\n",
    "        print('Epoch {}/{}'.format(epoch_num + 1, num_epochs))\n",
    "        n = 1\n",
    "        while True:\n",
    "            #try:\n",
    "                # 当完成一轮epoch时，计算epoch_length个rpn_accuracy的均值，输出相关信息，如果均值为0，则提示出错\n",
    "                if len(rpn_accuracy_rpn_monitor) == epoch_length and cfg.verbose:\n",
    "                    mean_overlapping_bboxes = float(sum(rpn_accuracy_rpn_monitor)) / len(rpn_accuracy_rpn_monitor)\n",
    "                    rpn_accuracy_rpn_monitor = []\n",
    "                    print(\n",
    "                        'Average number of overlapping bounding boxes from RPN = {} for {} previous iterations'.format(\n",
    "                            mean_overlapping_bboxes, epoch_length))\n",
    "                    if mean_overlapping_bboxes == 0:\n",
    "                        print('RPN is not producing bounding boxes that overlap'\n",
    "                              ' the ground truth boxes. Check RPN settings or keep training.')\n",
    "\n",
    "                # X：resize后的图片  Y：标定好的anchor和回归系数  img_data：原始图片的信息\n",
    "                X, Y, img_data, X_2 = next(data_gen_train)\n",
    "                # 训练1阶段的rpn\n",
    "                loss_rpn = model_rpn.train_on_batch(X, Y)\n",
    "                # 预测每个anchor的分数和回归系数, P_rpn[0]维度为(1,m,n,9), P_rpn[1]维度为(1,m,n,36)\n",
    "                P_rpn = model_rpn.predict_on_batch(X)\n",
    "                # 在feature map上生成按预测得分降序排列的proposals（即rois）\n",
    "                result = roi_helpers.rpn_to_roi(P_rpn[0], P_rpn[1], cfg, K.image_dim_ordering(), use_regr=True,\n",
    "                                                overlap_thresh=0.7,\n",
    "                                                max_boxes=5)\n",
    "                # 训练2阶段的classifier\n",
    "                x, y, num_logistic = data_gen_stage_2(result, img_data, sess, X_2, class_mapping, classes_count, iter_num, num_logistic)\n",
    "                loss_class = model_classifier.train_on_batch(x, y)\n",
    "\n",
    "                # 统计loss\n",
    "                losses[iter_num, 0] = loss_rpn[1]\n",
    "                losses[iter_num, 1] = loss_rpn[2]\n",
    "                losses[iter_num, 2] = loss_class[1]\n",
    "                losses[iter_num, 3] = loss_class[2]\n",
    "\n",
    "                # 更新进度条   #========== ('rpn_cls', np.mean(losses[:iter_num, 0])), ('rpn_regr', np.mean(losses[:iter_num, 1])),\n",
    "                iter_num += 1\n",
    "                progbar.update(iter_num,\n",
    "                               [('rpn_cls', np.mean(losses[:iter_num, 0])), ('rpn_regr', np.mean(losses[:iter_num, 1])),\n",
    "                                ('detector_cls', np.mean(losses[:iter_num, 2])),('detector_regr', np.mean(losses[:iter_num, 3]))])\n",
    "                n += 1\n",
    "                # 如果一个epoch结束，输出各个部分的平均误差\n",
    "                if iter_num == epoch_length:\n",
    "                    loss_rpn_cls = np.mean(losses[:, 0])\n",
    "                    loss_rpn_regr = np.mean(losses[:, 1])\n",
    "                    loss_class_cls = np.mean(losses[:, 2])\n",
    "                    loss_class_regr = np.mean(losses[:, 3])\n",
    "\n",
    "                    #=======mean_overlapping_bboxes = float(sum(rpn_accuracy_for_epoch)) / len(rpn_accuracy_for_epoch)\n",
    "                    #=======rpn_accuracy_for_epoch = []\n",
    "\n",
    "                    # 输出提示信息\n",
    "                    if cfg.verbose:\n",
    "                        #==========print('Mean number of bounding boxes from RPN overlapping ground truth boxes: {}'.format(\n",
    "                               #===========mean_overlapping_bboxes))\n",
    "                        print('Loss RPN classifier: {}'.format(loss_rpn_cls))\n",
    "                        print('Loss RPN regression: {}'.format(loss_rpn_regr))\n",
    "                        print('Loss Detector classifier: {}'.format(loss_class_cls))\n",
    "                        print('Loss Detector regression: {}'.format(loss_class_regr))\n",
    "                        print('Elapsed time: {}'.format(time.time() - start_time))\n",
    "\n",
    "                    # 当前整个epoch的总和损失  #=============loss_rpn_cls + loss_rpn_regr +\n",
    "                    curr_loss = loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr\n",
    "                    iter_num = 0\n",
    "                    start_time = time.time()\n",
    "                    '''\n",
    "                    # 1个epoch所有图片proposals区域，正样本anchors的高、宽趋势可视化\n",
    "                    x = range(len(num_width))\n",
    "                    y1 = num_width\n",
    "                    y2 = num_height\n",
    "                    plt.plot(x, y1, marker='o', color='r')\n",
    "                    plt.plot(x, y2, marker='*', color='b')\n",
    "                    # plt.show()\n",
    "                    # plt.savefig('plot.png',format='png')\n",
    "                    '''\n",
    "                    # 如果当前损失最小，则保存当前的参数\n",
    "                    if curr_loss < best_loss:\n",
    "                        if cfg.verbose:\n",
    "                            print('Total loss decreased from {} to {}, saving weights'.format(best_loss, curr_loss))\n",
    "                        best_loss = curr_loss\n",
    "                        model_classifier.save_weights(cfg.model_path)\n",
    "\n",
    "                    break\n",
    "    print(num_logistic)\n",
    "'''\n",
    "            except Exception as e:\n",
    "                print('Exception: {}'.format(e))\n",
    "                # save model\n",
    "                model_all.save_weights(cfg.model_path)\n",
    "                continue\n",
    "'''\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()\n",
    "    print('Training complete, exiting.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict image from ./00020_annotated_num_120/images/aug_3_012.png\n",
      "【RPN outputs】:\n",
      "coordinate:[1040.  400. 1056.  448.] prob: 5.0\n",
      "coordinate:[1360.  592. 1376.  608.] prob: 4.0\n",
      "coordinate:[1360.  608. 1376.  624.] prob: 3.0\n",
      "coordinate:[1456.  752. 1472.  784.] prob: 2.0\n",
      "coordinate:[1792.  640. 1808.  672.] prob: 1.0\n",
      "【8】\n",
      "coordinate:[1050.  416. 1057.  425.] prob: 0.9999703168869019\n",
      "【0】\n",
      "coordinate:[1048.  439. 1053.  450.] prob: 0.9998008608818054\n",
      "【9】\n",
      "coordinate:[1051.  399. 1053.  404.] prob: 0.9718182682991028\n",
      "【2】\n",
      "coordinate:[1047.  441. 1051.  447.] prob: 0.9999532699584961\n",
      "【7】\n",
      "coordinate:[1046.  446. 1048.  448.] prob: 0.998893678188324\n",
      "【4】\n",
      "coordinate:[1048.  417. 1050.  419.] prob: 0.9982838034629822\n",
      "【6】\n",
      "coordinate:[1051.  437. 1056.  442.] prob: 0.9876574277877808\n",
      "【3】\n",
      "coordinate:[1040.  445. 1042.  448.] prob: 0.9884258508682251\n",
      "【0】\n",
      "coordinate:[1369.  605. 1375.  609.] prob: 0.9996733665466309\n",
      "【8】\n",
      "coordinate:[1359.  605. 1366.  608.] prob: 0.9999905824661255\n",
      "【9】\n",
      "coordinate:[1371.  592. 1373.  593.] prob: 0.9756549596786499\n",
      "【2】\n",
      "coordinate:[1372.  606. 1376.  608.] prob: 0.9999058246612549\n",
      "【7】\n",
      "coordinate:[1370.  607. 1371.  608.] prob: 0.9976534247398376\n",
      "【3】\n",
      "coordinate:[1360.  607. 1362.  608.] prob: 0.9965043067932129\n",
      "【6】\n",
      "coordinate:[1371.  592. 1376.  594.] prob: 0.9798247814178467\n",
      "【4】\n",
      "coordinate:[1374.  598. 1376.  599.] prob: 0.9944867491722107\n",
      "【1】\n",
      "coordinate:[1361.  606. 1364.  607.] prob: 0.9533526301383972\n",
      "【0】\n",
      "coordinate:[1368.  621. 1373.  625.] prob: 0.9996587038040161\n",
      "【8】\n",
      "coordinate:[1359.  621. 1366.  624.] prob: 0.9999827146530151\n",
      "【9】\n",
      "coordinate:[1369.  608. 1372.  609.] prob: 0.9865236878395081\n",
      "【2】\n",
      "coordinate:[1372.  622. 1376.  624.] prob: 0.9999058246612549\n",
      "【7】\n",
      "coordinate:[1370.  623. 1371.  624.] prob: 0.9969128370285034\n",
      "【3】\n",
      "coordinate:[1360.  623. 1362.  624.] prob: 0.9950107336044312\n",
      "【6】\n",
      "coordinate:[1371.  608. 1376.  610.] prob: 0.9862685799598694\n",
      "【4】\n",
      "coordinate:[1370.  610. 1371.  611.] prob: 0.9948719143867493\n",
      "【1】\n",
      "coordinate:[1361.  622. 1364.  623.] prob: 0.909410297870636\n",
      "【8】\n",
      "coordinate:[1466.  778. 1473.  785.] prob: 0.999678373336792\n",
      "【9】\n",
      "coordinate:[1467.  751. 1469.  755.] prob: 0.9694572687149048\n",
      "【0】\n",
      "coordinate:[1465.  778. 1471.  785.] prob: 0.9962731599807739\n",
      "【2】\n",
      "coordinate:[1468.  780. 1472.  784.] prob: 0.9987012147903442\n",
      "【4】\n",
      "coordinate:[1470.  755. 1472.  757.] prob: 0.9831127524375916\n",
      "【7】\n",
      "coordinate:[1467.  782. 1469.  784.] prob: 0.9863055944442749\n",
      "【6】\n",
      "coordinate:[1467.  753. 1472.  756.] prob: 0.9656375050544739\n",
      "【3】\n",
      "coordinate:[1456.  782. 1458.  784.] prob: 0.9499509334564209\n",
      "【8】\n",
      "coordinate:[1799.  638. 1806.  644.] prob: 0.9998995065689087\n",
      "【0】\n",
      "coordinate:[1800.  666. 1805.  673.] prob: 0.9993489384651184\n",
      "【9】\n",
      "coordinate:[1803.  639. 1805.  643.] prob: 0.9785480499267578\n",
      "【2】\n",
      "coordinate:[1800.  668. 1804.  672.] prob: 0.9996281862258911\n",
      "【7】\n",
      "coordinate:[1800.  670. 1802.  672.] prob: 0.9938414096832275\n",
      "【4】\n",
      "coordinate:[1803.  658. 1805.  659.] prob: 0.9938866496086121\n",
      "【6】\n",
      "coordinate:[1803.  641. 1808.  644.] prob: 0.9811540246009827\n",
      "【3】\n",
      "coordinate:[1792.  643. 1794.  645.] prob: 0.9289632439613342\n",
      "result saved into  ./result_images/aug_3_012.png\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from keras import backend as K\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "import roi_helpers\n",
    "import argparse\n",
    "import os\n",
    "import resnet as nn\n",
    "from visualize import draw_boxes_and_label_on_image\n",
    "from net_design_2nd import stage_2_net_vgg\n",
    "from anchor_2nd import anchors_generation, sliding_anchors_all\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "\n",
    "def format_img_size(img, cfg):\n",
    "    \"\"\" 缩放图片尺寸，短边为600 \"\"\"\n",
    "    img_min_side = float(cfg.im_size)\n",
    "    (height, width, _) = img.shape\n",
    "\n",
    "    if width <= height:\n",
    "        ratio = img_min_side / width\n",
    "        new_height = int(ratio * height)\n",
    "        new_width = int(img_min_side)\n",
    "    else:\n",
    "        ratio = img_min_side / height\n",
    "        new_width = int(ratio * width)\n",
    "        new_height = int(img_min_side)\n",
    "    img = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_CUBIC)\n",
    "    return img, ratio\n",
    "\n",
    "\n",
    "def format_img_channels(img, cfg):\n",
    "    \"\"\" 每个channel减去像素均值，将channel放在第一维，然后在前面增加一个维度 \"\"\"\n",
    "    # img = img[:, :, (2, 1, 0)]\n",
    "    img = img.astype(np.float32)\n",
    "    \n",
    "    img[:, :, 0] -= cfg.img_channel_mean[0]\n",
    "    img[:, :, 1] -= cfg.img_channel_mean[1]\n",
    "    img[:, :, 2] -= cfg.img_channel_mean[2]\n",
    "    \n",
    "    img /= cfg.img_scaling_factor\n",
    "    # img = np.transpose(img, (2, 0, 1))\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img\n",
    "\n",
    "\n",
    "def format_img(img, C):\n",
    "    \"\"\" formats an image for model prediction based on config \"\"\"\n",
    "    ratio = 1\n",
    "    img = format_img_channels(img, C)\n",
    "    return img, ratio\n",
    "\n",
    "\n",
    "def get_real_coordinates(ratio, x1, y1, x2, y2):\n",
    "    \"\"\"\n",
    "    将坐标值从resize后的图片映射到原始图片\n",
    "    \"\"\"\n",
    "    real_x1 = int(round(x1 // ratio))\n",
    "    real_y1 = int(round(y1 // ratio))\n",
    "    real_x2 = int(round(x2 // ratio))\n",
    "    real_y2 = int(round(y2 // ratio))\n",
    "\n",
    "    return real_x1, real_y1, real_x2, real_y2\n",
    "\n",
    "\n",
    "def predict_single_image(img_path, model_rpn, model_classifier, cfg, class_mapping):\n",
    "    \"\"\"\n",
    "    预测单张图片\n",
    "    :param img_path: 图片路径\n",
    "    :param model_rpn: rpn模型\n",
    "    :param model_classifier: 目标检测模型\n",
    "    :param cfg: 配置参数\n",
    "    :param class_mapping: 类别映射\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    img = cv2.imread(img_path)  # 读取图片\n",
    "\n",
    "    if img is None:\n",
    "        print('reading image failed.')\n",
    "        exit(0)\n",
    "\n",
    "    # print(class_mapping)\n",
    "\n",
    "    X, ratio = format_img(img, cfg)  # 预处理图片（缩放、变换维度）\n",
    "    '''\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        X = np.transpose(X, (0, 2, 3, 1))\n",
    "    '''\n",
    "    # 得到所有anchor的分类得分、回归参数以及feature map\n",
    "    P_rpn = model_rpn.predict_on_batch(X)\n",
    "\n",
    "    # 得到proposals (rois)\n",
    "    proposals = roi_helpers.rpn_to_roi(P_rpn[0], P_rpn[1], cfg, K.image_dim_ordering(), use_regr=True,\n",
    "                                                overlap_thresh=0.7,\n",
    "                                                max_boxes=5)\n",
    "\n",
    "    rpn_outputs = []  # 存放proposals\n",
    "\n",
    "    score = 5\n",
    "    # 将proposal坐标从feature map映射回输入图片\n",
    "    for proposal in proposals:\n",
    "        rpn_outputs.append(\n",
    "            [cfg.rpn_stride * proposal[0], cfg.rpn_stride * proposal[1],\n",
    "             cfg.rpn_stride * proposal[2], cfg.rpn_stride * proposal[3], score])\n",
    "        score -= 1\n",
    "\n",
    "    # for box in rpn_outputs:\n",
    "    # nms\n",
    "    boxes_nms = roi_helpers.non_max_suppression_fast(rpn_outputs, overlap_thresh=0.8)\n",
    "    rpn_outputs = boxes_nms\n",
    "    print(\"【RPN outputs】:\")\n",
    "    for b in boxes_nms:\n",
    "        # 将坐标映射回原始图片\n",
    "        b[0], b[1], b[2], b[3] = get_real_coordinates(ratio, b[0], b[1], b[2], b[3])\n",
    "        print('coordinate:{} prob: {}'.format(b[0: 4], b[-1]))\n",
    "\n",
    "    # 将rois从原图中裁剪出来，并记录裁剪尺度和裁剪比例\n",
    "    image = Image.fromarray(img.astype('uint8'))\n",
    "    resized_width = 80\n",
    "    resized_height = 160\n",
    "    imgs_crop = []  # 存放裁剪后的图片\n",
    "    crop_scales = []  # 存放每个roi从原图中的裁剪尺度\n",
    "    crop_ratios = []  # 存放每个roi的缩放比\n",
    "    for roi in rpn_outputs:\n",
    "        w = roi[2] - roi[0]\n",
    "        h = roi[3] - roi[1]\n",
    "        ratio_w = resized_width / w\n",
    "        ratio_h = resized_height / h\n",
    "        crop_ratios.append([ratio_w, ratio_h])\n",
    "        crop_scales.append([round(roi[0]), round(roi[1])])\n",
    "        prop_crop = image.crop([roi[0], roi[1], roi[2], roi[3]])\n",
    "        prop_crop = img_to_array(prop_crop)\n",
    "        prop_pic = cv2.resize(prop_crop, (resized_width, resized_height))\n",
    "        imgs_crop.append(prop_pic)\n",
    "\n",
    "    base_anchors = anchors_generation(16, [0.5 ** (1.0 / 3.0), 1, 2 ** (1.0 / 3.0)],\n",
    "                                      [0.5, 0.5 ** (1.0 / 2.0), 1, 2 ** (1.0 / 3.0), 2 ** (1.0 / 2.0), 2])\n",
    "    all_anchors = sliding_anchors_all((10, 20), (8, 8), base_anchors)\n",
    "\n",
    "    final_boxes = {}\n",
    "    for i, img_crop in enumerate(imgs_crop):\n",
    "        p_cls, p_regr = model_classifier.predict_on_batch(img_crop[np.newaxis, :, :, :])\n",
    "        boxes = {}\n",
    "        bbox_threshold = 0.9\n",
    "        # 遍历每个anchor\n",
    "        for ii in range(p_cls.shape[1]):\n",
    "            # 如果当前anchor为某类的最大概率小于阈值，或者最大概率对应的是背景类，则丢弃\n",
    "            if np.max(p_cls[0, ii, :]) < bbox_threshold or np.argmax(p_cls[0, ii, :]) == (p_cls.shape[2] - 1):\n",
    "                continue\n",
    "            cls_num = np.argmax(p_cls[0, ii, :])  # 最大概率类别对应的下标\n",
    "            if cls_num not in boxes.keys():\n",
    "                boxes[cls_num] = []\n",
    "\n",
    "            # 边框回归\n",
    "            x1, y1, x2, y2 = regr_revise(all_anchors[ii, :], p_regr[0, ii, 4*cls_num: 4*(cls_num+1)])\n",
    "            boxes[cls_num].append([all_anchors[ii, 0], all_anchors[ii, 1],\n",
    "                                   all_anchors[ii, 2], all_anchors[ii, 3], np.max(p_cls[0, ii, :])])\n",
    "#             boxes[cls_num].append([x1, y1, x2, y2, np.max(p_cls[0, ii, :])])\n",
    "\n",
    "            # print('================>')\n",
    "            # print('回归前坐标：{}'.format(all_anchors[ii, :]))\n",
    "            # print('回归参数：{}'.format(p_regr[0, ii, 4*cls_num: 4*(cls_num+1)]))\n",
    "            # print('回归后坐标：{}'.format([x1, y1, x2, y2]))\n",
    "            # print('<================')\n",
    "\n",
    "        for cls_num, box in boxes.items():\n",
    "            # nms\n",
    "            boxes_nms = roi_helpers.non_max_suppression_fast(box, overlap_thresh=0.3, max_boxes=1)\n",
    "            boxes[cls_num] = boxes_nms\n",
    "            for b in boxes_nms:\n",
    "                # 将坐标映射回原始小图片\n",
    "                b[0] = round(b[0] / crop_ratios[i][0])\n",
    "                b[1] = round(b[1] / crop_ratios[i][1])\n",
    "                b[2] = round(b[2] / crop_ratios[i][0])\n",
    "                b[3] = round(b[3] / crop_ratios[i][1])\n",
    "                # 将坐标映射回原始大图片\n",
    "                b[0] += crop_scales[i][0]\n",
    "                b[1] += crop_scales[i][1]\n",
    "                b[2] += crop_scales[i][0]\n",
    "                b[3] += crop_scales[i][1]\n",
    "\n",
    "                print('【{}】'.format(class_mapping[cls_num]))\n",
    "                print('coordinate:{} prob: {}'.format(b[0: 4], b[-1]))\n",
    "                if cls_num not in final_boxes.keys():\n",
    "                    final_boxes[cls_num] = []\n",
    "                final_boxes[cls_num].append([b[0], b[1], b[2], b[3], b[4]])\n",
    "\n",
    "    # 绘图保存\n",
    "    img = draw_boxes_and_label_on_image(img, class_mapping, final_boxes)\n",
    "    result_path = './result_images/{}.png'.format(os.path.basename(img_path).split('.')[0])\n",
    "    print('result saved into ', result_path)\n",
    "    cv2.imwrite(result_path, img)\n",
    "\n",
    "\n",
    "def regr_revise(anchor, regr):\n",
    "    \"\"\"\n",
    "    第1阶段bbox_transform函数定义的回归目标在4个偏移量(dx,dy,dw,dh)基础上，做位置修正\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    x_target_center = regr[0] * (anchor[2] - anchor[0]) + (anchor[2] + anchor[0]) / 2.0\n",
    "    y_target_center = regr[1] * (anchor[3] - anchor[1]) + (anchor[3] + anchor[1]) / 2.0\n",
    "    w_target = np.exp(regr[2]) * (anchor[2] - anchor[0])\n",
    "    h_target = np.exp(regr[3]) * (anchor[3] - anchor[1])\n",
    "    x1_target = x_target_center - w_target / 2.0\n",
    "    y1_target = y_target_center - h_target / 2.0\n",
    "    x2_target = x_target_center + w_target / 2.0\n",
    "    y2_target = y_target_center + h_target / 2.0\n",
    "    return x1_target, y1_target, x2_target, y2_target\n",
    "\n",
    "\n",
    "def predict(args_):\n",
    "    \"\"\"\n",
    "    预测图片\n",
    "    :param args_: 从命令行获取的参数\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    path = args_  # 图片路径\n",
    "    # 加载配置文件\n",
    "    with open('config.pickle', 'rb') as f_in:\n",
    "        cfg = pickle.load(f_in)\n",
    "    # cfg.use_horizontal_flips = False\n",
    "    # cfg.use_vertical_flips = False\n",
    "    # cfg.rot_90 = False\n",
    "\n",
    "    class_mapping = cfg.class_mapping\n",
    "    if 'bg' not in class_mapping:\n",
    "        class_mapping['bg'] = len(class_mapping)\n",
    "    class_mapping = {v: k for k, v in class_mapping.items()}  # 键值互换\n",
    "\n",
    "    input_shape_img = (None, None, 3)\n",
    "    img_input = Input(shape=input_shape_img)\n",
    "\n",
    "    # 定义基础网络\n",
    "    shared_layers = nn.nn_base(img_input, trainable=True)\n",
    "\n",
    "    # 定义RPN\n",
    "    num_anchors = len(cfg.anchor_box_scales) * len(cfg.anchor_box_ratios)\n",
    "    rpn_layers = nn.rpn(shared_layers, num_anchors)\n",
    "\n",
    "    # 定义检查网络\n",
    "    small_img_input = Input(shape=(160, 80, 3))\n",
    "    classifier = stage_2_net_vgg(len(class_mapping), small_img_input)\n",
    "\n",
    "    model_rpn = Model(img_input, rpn_layers)\n",
    "    model_classifier = Model(small_img_input, classifier)\n",
    "\n",
    "    # 加载权重\n",
    "    model_rpn.load_weights('model_trained/model_final_1st.hdf5', by_name=True)\n",
    "    model_classifier.load_weights('model_trained/model_final.hdf5', by_name=True)\n",
    "\n",
    "    # 编译模型\n",
    "    model_rpn.compile(optimizer='sgd', loss='mse')\n",
    "    model_classifier.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "    if os.path.isdir(path):\n",
    "        for idx, img_name in enumerate(sorted(os.listdir(path))):\n",
    "            if not img_name.lower().endswith(('.bmp', '.jpeg', '.jpg', '.png', '.tif', '.tiff')):\n",
    "                continue\n",
    "            print(img_name)\n",
    "            predict_single_image(os.path.join(path, img_name), model_rpn,\n",
    "                                 model_classifier, cfg, class_mapping)\n",
    "    elif os.path.isfile(path):\n",
    "        print('predict image from {}'.format(path))\n",
    "        predict_single_image(path, model_rpn, model_classifier, cfg, class_mapping)\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # 00020_annotated_num/images/aug_3_012.png\n",
    "    parser.add_argument('--path', '-p', default='./00020_annotated_num_120/images', help='image path')\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # args = parse_args()\n",
    "    predict('./00020_annotated_num_120/images/aug_3_012.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
